# 课程目标

- 掌握线性代数的基本操作
- 掌握矩阵的基本操作
- 掌握矩阵和向量在实际开发中的应用

# 线性系统

## 什么是系统

系统是可以理解为有一个输入, 并且一般会有一个输出

- 语言识别

  > ![image-20230807114857822](https://markdown-hesj.oss-cn-guangzhou.aliyuncs.com/image-20230807114857822.png)

- 聊天系统

  > ![image-20230807114847101](https://markdown-hesj.oss-cn-guangzhou.aliyuncs.com/image-20230807114847101.png)

- 通信系统

  > ![image-20230807114758021](https://markdown-hesj.oss-cn-guangzhou.aliyuncs.com/image-20230807114758021.png)

## 线性系统

- 倍乘法

  > ![image-20230807115249939](https://markdown-hesj.oss-cn-guangzhou.aliyuncs.com/image-20230807115249939.png)

- 累加法

  > ![image-20230807115311784](https://markdown-hesj.oss-cn-guangzhou.aliyuncs.com/image-20230807115311784.png)

## 向量的线性计算

- 倍乘法

> $\begin{bmatrix}
> 1\\2
> \end{bmatrix}\longrightarrow 系统 \longrightarrow \begin{bmatrix}
> 3\\4\\5
> \end{bmatrix}$                       $k\begin{bmatrix}
> 1\\2
> \end{bmatrix}\longrightarrow 系统 \longrightarrow k\begin{bmatrix}
> 3\\4\\5
> \end{bmatrix} $

- 累加法

> $\begin{bmatrix}
> 1\\2
> \end{bmatrix}\longrightarrow 系统 \longrightarrow \begin{bmatrix}
> 3\\4\\5
> \end{bmatrix}$                 $\begin{bmatrix}
> 1\\2
> \end{bmatrix}+\begin{bmatrix}
> 3\\4
> \end{bmatrix}\longrightarrow 系统 \longrightarrow \begin{bmatrix}
> 3\\4\\5
> \end{bmatrix}+\begin{bmatrix}
> 6\\7\\8
> \end{bmatrix} $
>
> $\begin{bmatrix}
> 3\\4
> \end{bmatrix}\longrightarrow 系统 \longrightarrow \begin{bmatrix}
> 6\\7\\8
> \end{bmatrix}$                 $\begin{bmatrix}
> 4\\6
> \end{bmatrix}\longrightarrow 系统 \longrightarrow \begin{bmatrix}
> 9\\11\\13
> \end{bmatrix}$ 

如果一个系统同时满足倍乘法和累加法, 那么这个系统就是一个线性系统

如果一个系统是线性系统, 那么就必须同时满足倍乘法和累加法

## 思考

> $x\longrightarrow 系统 \longrightarrow  x^2$

![image-20230807154904387](https://markdown-hesj.oss-cn-guangzhou.aliyuncs.com/image-20230807154904387.png)

> - 倍乘操作
>
> ![image-20230807154921453](https://markdown-hesj.oss-cn-guangzhou.aliyuncs.com/image-20230807154921453.png)

> - 累加操作
>
> ![image-20230807154939779](https://markdown-hesj.oss-cn-guangzhou.aliyuncs.com/image-20230807154939779.png)

`转置操作` 

> ![image-20230807155122766](https://markdown-hesj.oss-cn-guangzhou.aliyuncs.com/image-20230807155122766.png)

> ![image-20230807155141344](https://markdown-hesj.oss-cn-guangzhou.aliyuncs.com/image-20230807155141344.png)

> ![image-20230807155310539](https://markdown-hesj.oss-cn-guangzhou.aliyuncs.com/image-20230807155310539.png)
>
> ![image-20230807155409826](images/image-20230807155409826.png)

# 向量及其运算

向量是数学中的基本概念，它在许多领域中都有应用，包括物理、工程、计算机科学和统计。向量有许多重要的性质和运算。

本质上就是一个数组, 由N个维度组成, 其表达式为

```python
X =(X1,X2,X3,...,Xn)
# 其中X在几何中代表一个点
# X1,X2,X3 ...Xn是X的多个维度
# 在生活中的案例
# X: 代表一个相亲男: X1: 年龄, X2: 身高, X3: 职业, Xn:财富
```

> ![image-20230807160543962](https://markdown-hesj.oss-cn-guangzhou.aliyuncs.com/image-20230807160543962.png)

> ![image-20230529230242509](https://markdown-hesj.oss-cn-guangzhou.aliyuncs.com/image-20230529230242509-1691395528925.png)

> `向量的分量称之为维度, n维向量集合的全体就构成了n维欧式空间`
> $$
> R^n
> $$

# 行向量和列向量

行向量是按行把向量排开,列向量是按列把向量排开

$$
\begin{bmatrix}
a & b & c
\end{bmatrix}
$$

$$
\begin{bmatrix}
a \\
b \\
c \\
\end{bmatrix}
$$

`在数学中我们更多的把数据写成列向量，在编程语言中更多的把数据存成行向量`

# 向量的基本运算

## 向量加法

向量的加法是基于对应元素的加法的。其结果就是一个新的向量，新向量的每个元素是相应的两个向量的同位置元素之和。

如果我们有两个向量 u 和 v，其定义如下：

- **u** = (a1, a2, ..., an)
- **v** = (b1, b2, ..., bn)

那么 **u + v** 的结果就是一个新的向量，该向量的每个元素是 u 和 v 的同位置元素之和：

- **u + v** = (a1 + b1, a2 + b2, ..., an + bn)

例如，如果 **u** = (1, 2, 3) 和 **v** = (4, 5, 6)，那么 **u + v** = (1+4, 2+5, 3+6) = (5, 7, 9)。

这就是向量的加法。请注意，`只有维数相同的向量`才可以进行加法运算。


向量 **u** 和向量 **v** 定义如下：

$$
\mathbf{u} = \begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix}
\quad
\mathbf{v} = \begin{bmatrix} 4 \\ 5 \\ 6 \end{bmatrix}
$$

则 **u + v** 的结果是：

$$
\mathbf{u} + \mathbf{v} = \begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix} + \begin{bmatrix} 4 \\ 5 \\ 6 \end{bmatrix} = \begin{bmatrix} 1+4 \\ 2+5 \\ 3+6 \end{bmatrix} = \begin{bmatrix} 5 \\ 7 \\ 9 \end{bmatrix}
$$

## 数乘运算

它是一个数和这个向量每个分量相乘

假设我们有一个列向量**v**和一个标量 a，定义如下：

$$
\mathbf{v} = \begin{bmatrix} 3 \\ 5 \\ 7 \end{bmatrix}
$$

$$
a = 2
$$

则 a***v** 的结果是：

$$
a \cdot \mathbf{v} = 2 \cdot \begin{bmatrix} 3 \\ 5 \\ 7 \end{bmatrix} = \begin{bmatrix} 2 \cdot 3 \\ 2 \cdot 5 \\ 2 \cdot 7 \end{bmatrix} = \begin{bmatrix} 6 \\ 10 \\ 14 \end{bmatrix}
$$

## 转置

把列向量变成行向量, 把行向量变成列向量

向量v 定义如下：

$$
\mathbf{v} = \begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix}
$$

向量 v 的转置为：

$$
\mathbf{v}^T = \begin{bmatrix} 1 & 2 & 3 \end{bmatrix}
$$

## 向量的内积

向量的内积，也称为点积dot，是一种将两个向量组合成单个标量的运算。

设 a,b 是两个 n 维向量，他们的内积或点积定义为：

$$
\mathbf{a} = \begin{bmatrix} a_1 \\ a_2 \\ \vdots \\ a_n \end{bmatrix} 和 \mathbf{b} = \begin{bmatrix} b_1 \\ b_2 \\ \vdots \\ b_n \end{bmatrix} \\
\mathbf{a^T} \cdot \mathbf{b} = a_1 b_1 + a_2 b_2 + \cdots + a_n b_n
$$

例如，如果 
$$
\mathbf{v} = \begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix} 和 \mathbf{w} = \begin{bmatrix} 4 \\ 5 \\ 6 \end{bmatrix}
\\
\mathbf{v}^T = \begin{bmatrix} 1 & 2 &3 \end{bmatrix} 和 \mathbf{w} = \begin{bmatrix} 4 \\ 5 \\ 6 \end{bmatrix}
$$
那么他们的内积是：
$$
\mathbf{v}^T \cdot \mathbf{w} = 1 \cdot 4 + 2 \cdot 5 + 3 \cdot 6 = 32
$$

## 向量的外积(张量积)

外积的计算不要求两个向量具有相同的维度。这与向量的点积（内积）不同，后者要求两个向量必须具有相同的维度。在外积中，如果一个向量是 m-维的，另一个向量是 n-维的，那么结果将是一个 m×n 的矩阵。

例如，如果 
$$
\mathbf{v} = \begin{bmatrix} 1 \\ 2  \end{bmatrix} 和 \mathbf{w} = \begin{bmatrix} 4 \\ 5 \\ 6 \end{bmatrix}
\\
\mathbf{v}^T = \begin{bmatrix} 1 & 2  \end{bmatrix} 和 \mathbf{w} = \begin{bmatrix} 4 \\ 5 \\ 6 \end{bmatrix}
$$
那么他们的内积是：
$$
\mathbf{v}^T \cdot \mathbf{w} = \begin{bmatrix}
1*4 & 1*5 & 1*6 \\
2*4 & 2*5 & 2*6 \\
\end{bmatrix}
$$

## 向量的范数

### L1范数

向量的 L1 范数，也被称为`曼哈顿范数`或者`曼哈顿距离`，是向量中所有元素绝对值的总和。

对于一个 n 维向量 a = [a1, a2, ..., an] ，它的 L1 范数定义为：

L1(a) = |a1| + |a2| + ... + |an|

这个范数得名于它衡量的是在一个网格（如城市街区）中从原点到向量表示的点的最短距离，就像在曼哈顿街区中行走一样。

例如，向量 a = [1, -2, 3] 的 L1 范数就是 |1| + |-2| + |3| = 1 + 2 + 3 = 6 。

### L2范数

向量的 L2 范数，也被称为`欧几里得范数`或`欧几里得距离`，是向量中所有元素平方和的平方根。对于一个 n 维向量 a = [a1, a2, ..., an] ，它的 L2 范数定义为：

$L2(a) = \sqrt{(a_1² + a_2² + ... + a_n²)}$

这是我们在日常生活中最常见的距离概念，例如，我们需要从一个点移动到另一个点，我们通常会考虑直线距离，这就是 L2 范数的直观解释。

例如，向量 a = [1, 2, 3] 的 L2 范数就是 $\sqrt{(1² + 2² + 3²)} = \sqrt{(14)}$。

> ![image-20230530093013824](https://markdown-hesj.oss-cn-guangzhou.aliyuncs.com/image-20230530093013824.png)

# 矩阵的运算

矩阵是一个按照长方阵列排列的复数或实数集合，构成了矩形的阵列，可以用来表示数据或进行数据操作。在数学、物理学和工程学等多个领域中，矩阵都是非常重要的工具，尤其是在线性代数中，矩阵是基本的数学结构。

**矩阵的基本组成**

- **元素**：矩阵由称为元素的项组成，这些元素可以是数字、符号或数学表达式。
- **行和列**：矩阵中的元素排成若干行和列。行是水平元素的集合，列是垂直元素的集合。

例如，一个2行3列的矩阵可以写成：
$$
\begin{bmatrix}
a_{11} & a_{12} & a_{12} \\
a_{21} & a_{22} & a_{23} \\
\end{bmatrix}
$$


矩阵的基本运算包括矩阵的加法、减法、标量乘法、矩阵乘法以及矩阵的转置等。

1. **矩阵加法**：两个矩阵相加，前提是这两个矩阵的`维度`必须一样，即行数和列数都相同，对应位置的元素直接相加即可。
2. **矩阵减法**：矩阵的减法与加法类似，也需要两个矩阵的维度一样，对应位置的元素直接相减。
3. **标量乘法**：一个标量乘以一个矩阵，就是将这个标量与矩阵的每一个元素相乘。
4. **矩阵乘法**：矩阵A的列数必须与矩阵B的行数相同，这样才能进行矩阵乘法。结果矩阵的元素是由A矩阵的行与B矩阵的列的对应元素的乘积之和得到的。
5. **矩阵的转置**：矩阵的转置是将矩阵的行列互换得到的新矩阵，即原矩阵的第i行第j列的元素变成新矩阵的第j行第i列的元素。

## **矩阵加法**

对于两个2x2的矩阵进行加法，可以表示如下
$$
\begin{bmatrix}
a_{11} & a_{12} \\
a_{21} & a_{22} \\
\end{bmatrix}
+
\begin{bmatrix}
b_{11} & b_{12} \\
b_{21} & b_{22} \\
\end{bmatrix}
=
\begin{bmatrix}
a_{11}+b_{11} & a_{12}+b_{12} \\
a_{21}+b_{21} & a_{22}+b_{22} \\
\end{bmatrix}
$$

## **标量乘法**

对于一个标量k与一个2x2的矩阵进行乘法，可以表示如下：
$$
k \cdot
\begin{bmatrix}
a_{11} & a_{12} \\
a_{21} & a_{22} \\
\end{bmatrix}
=
\begin{bmatrix}
k \cdot a_{11} & k \cdot a_{12} \\
k \cdot a_{21} & k \cdot a_{22} \\
\end{bmatrix}
$$

## **矩阵乘法**

对于两个2x2的矩阵进行乘法,可以表示如下：
$$
\begin{bmatrix}
a_{11} & a_{12} \\
a_{21} & a_{22} \\
\end{bmatrix}
\cdot
\begin{bmatrix}
b_{11} & b_{12} \\
b_{21} & b_{22} \\
\end{bmatrix}
=
\begin{bmatrix}
a_{11} \cdot b_{11} + a_{12} \cdot b_{21} & a_{11} \cdot b_{12} + a_{12} \cdot b_{22} \\
a_{21} \cdot b_{11} + a_{22} \cdot b_{21} & a_{21} \cdot b_{12} + a_{22} \cdot b_{22} \\
\end{bmatrix}
$$

## **矩阵的转置**

对于一个2x2的矩阵进行转置，可以表示如下：
$$
\begin{bmatrix}
a_{11} & a_{12} \\
a_{21} & a_{22} \\
\end{bmatrix}^T
=
\begin{bmatrix}
a_{11} & a_{21} \\
a_{12} & a_{22} \\
\end{bmatrix}
$$

# 案例实战

## 房价预测模型

设计一个基于神经元的房价预测模型，可以构建一个简单的线性模型，该模型使用三个特征：面积（平方米）、楼龄（年）、和卧室数量。这个模型将演示如何通过单一神经元处理输入特征，并使用矩阵和向量的形式来表示权重和偏置项，最后输出预测的房价。

## 整体模型描述

**输入特征向量**

我们的模型将接受一个三维特征向量 x，其各维度分别表示：

- $x_1$：面积（平方米）
- $x_2$：楼龄（年）
- $x_3$：卧室数量

这个特征向量可以表示为： $\mathbf{x} = \begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix}$

**权重向量和偏置**

神经元将具有一个相应的权重向量 w 和一个偏置项 b。权重表示每个特征对于预测输出的重要性，偏置项提供了一个调整后的基线输出。

- 权重向量 ： $\mathbf{w} = \begin{bmatrix} w_1 \\ w_2 \\ w_3 \end{bmatrix}$

  $w_1,w_2,w_3$ 分别对应面积、楼龄和卧室数量的权重。

- 偏置项 b 是一个标量。

**模型的输出（预测房价）**

神经元的输出是通过将输入特征向量与权重向量进行点积, 然后加上偏置项来计算的： $y=w^Tx+b$

这里的y是模型预测的房价。

**计算步骤**

1. **点积运算**：计算权重向量 w 和输入向量 x 的点积。
2. **加上偏置**：将点积结果加上偏置项b。
3. **输出结果**：得到的总和即为预测的房价。

> ![image-20240929154826448](https://markdown-hesj.oss-cn-guangzhou.aliyuncs.com/image-20240929154826448.png)

## 案例说明

假设我们有以下的权重和偏置：

权重向量: $\mathbf{w} = \begin{bmatrix} 0.5 \\ -0.3 \\ 0.2 \end{bmatrix}$

偏置: b = 50

当输入一个具体的特征向量，比如:

面积为120平方米，楼龄为10年，卧室数量为3。

特征向量: $\mathbf{x} = \begin{bmatrix} 120 \\ 10 \\ 3 \end{bmatrix}$

则预测房价计算: $y=\begin{bmatrix} 0.5 & -0.5 & 0.2 \end{bmatrix}\begin{bmatrix} 120 \\ 10 \\ 3 \end{bmatrix}+50=0.5*120+(-0.5)*10+0.2*3+50=60-5+0.6+50=107.6$

所以预测的房价是107.6万元。

# 作业

> 需求, 现在要设计一个自动驾驶的模型, 其中影响自动驾驶的一些因素有:
>
> $x_1$:行人距离
>
> $x_2$:前车距离
>
> $x_3$:道路状况
>
> 对于自动驾驶, 需要控制的有
>
> $y_1$:油门
>
> $y_2$:刹车
>
> $y_3$:转弯
>
> 其中每个控制功能都和上面的因素存在线性关系
>
> 即:
>
> $y_1=w_{11}*x_1+w_{12}*x_2+w_{13}*x_3$
>
> $y_2=w_{21}*x_1+w_{22}*x_2+w_{23}*x_3$
>
> $y_3=w_{31}*x_1+w_{32}*x_2+w_{33}*x_3$

> ![image-20230807183226649](https://markdown-hesj.oss-cn-guangzhou.aliyuncs.com/image-20230807183226649.png)

> 使用矩阵表示
>
> $X=\begin{bmatrix}
> x1\\x2\\x3
> \end{bmatrix}$
>
> 其中x1 代表行人距离, x2 代表前车距离, x3 代表道路状况
>
> $Y=\begin{bmatrix}
> y1\\y2\\y3
> \end{bmatrix}$
>
> 其中y1 代表油门控制, y2 代表刹车控制, y3 代表转弯控制
>
> $W=\begin{bmatrix}
> w_{11}&w_{12}&w_{13} \\
> w_{21}&w_{22}&w_{23} \\
> w_{31}&w_{32}&w_{33} 
> \end{bmatrix}$

请通过具体的案例, 设置具体的数值, 完成上面的一个计算